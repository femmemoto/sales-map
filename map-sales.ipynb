{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import us\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Prep: ###\n",
    "* Read in file, skipping over top 7 rows\n",
    "* Convert 'order postal' to category dtype (first experiment with this dtype, look for weirdness...)\n",
    "* Load function to clean column names (used as db is being created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date/time</th>\n",
       "      <th>settlement id</th>\n",
       "      <th>type</th>\n",
       "      <th>sku</th>\n",
       "      <th>quantity</th>\n",
       "      <th>order city</th>\n",
       "      <th>order state</th>\n",
       "      <th>order postal</th>\n",
       "      <th>product sales</th>\n",
       "      <th>other</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feb 1, 2016 12:28:08 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MARION</td>\n",
       "      <td>OH</td>\n",
       "      <td>43302-5231</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb 1, 2016 2:09:21 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Refund</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TENAFLY</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07670-3014</td>\n",
       "      <td>-32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feb 1, 2016 3:19:52 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MILILANI</td>\n",
       "      <td>HI</td>\n",
       "      <td>96789-2046</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feb 1, 2016 3:35:39 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BLOOMFIELD</td>\n",
       "      <td>MO</td>\n",
       "      <td>63825-9505</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>11.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb 1, 2016 5:49:49 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CLIFTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07011-3215</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feb 3, 2016 1:52:11 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>REDMOND</td>\n",
       "      <td>WA</td>\n",
       "      <td>98052-6122</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feb 3, 2016 1:54:22 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NASHVILLE</td>\n",
       "      <td>TN</td>\n",
       "      <td>37212-4810</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Feb 3, 2016 2:17:18 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LAKE ZURICH</td>\n",
       "      <td>IL</td>\n",
       "      <td>60047-2839</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Feb 3, 2016 1:40:23 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALEXANDRIA</td>\n",
       "      <td>VA</td>\n",
       "      <td>22314-4755</td>\n",
       "      <td>49.99</td>\n",
       "      <td>0</td>\n",
       "      <td>33.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Feb 4, 2016 8:28:33 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KELLER</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>76248-4148</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date/time  settlement id    type    sku  quantity  \\\n",
       "0  Feb 1, 2016 12:28:08 AM PST     6048826701   Order  sku01       1.0   \n",
       "1   Feb 1, 2016 2:09:21 PM PST     6048826701  Refund  sku02       1.0   \n",
       "2   Feb 1, 2016 3:19:52 PM PST     6048826701   Order  sku02       1.0   \n",
       "3   Feb 1, 2016 3:35:39 PM PST     6048826701   Order  sku03       1.0   \n",
       "4   Feb 1, 2016 5:49:49 PM PST     6048826701   Order  sku01       1.0   \n",
       "5   Feb 3, 2016 1:52:11 AM PST     6048826701   Order  sku02       1.0   \n",
       "6   Feb 3, 2016 1:54:22 AM PST     6048826701   Order  sku02       1.0   \n",
       "7   Feb 3, 2016 2:17:18 AM PST     6048826701   Order  sku01       1.0   \n",
       "8   Feb 3, 2016 1:40:23 PM PST     6048826701   Order  sku04       1.0   \n",
       "9   Feb 4, 2016 8:28:33 AM PST     6048826701   Order  sku01       1.0   \n",
       "\n",
       "    order city order state order postal  product sales other   total  \n",
       "0       MARION          OH   43302-5231          35.00     0   26.12  \n",
       "1      TENAFLY          NJ   07670-3014         -32.99     0  -29.03  \n",
       "2     MILILANI          HI   96789-2046          32.99     0   24.02  \n",
       "3   BLOOMFIELD          MO   63825-9505          16.99     0   11.77  \n",
       "4      CLIFTON          NJ   07011-3215          35.00     0   26.12  \n",
       "5      REDMOND          WA   98052-6122          32.99     0   24.02  \n",
       "6    NASHVILLE          TN   37212-4810          32.99     0   24.02  \n",
       "7  LAKE ZURICH          IL   60047-2839          35.00     0   26.12  \n",
       "8   ALEXANDRIA          VA   22314-4755          49.99     0   33.73  \n",
       "9       KELLER       TEXAS   76248-4148          35.00     0   26.12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user = 'test_user'\n",
    "\n",
    "encode = 'latin_1'\n",
    "skip_rows = 7\n",
    "df = pd.read_csv('test-sales.csv', encoding = encode, skiprows=skip_rows, dtype={'order postal': 'str'})\n",
    "\n",
    "# Would like to play with pandas dtype 'category' but breaks the zipcode string operations so for future development:\n",
    "# df = pd.read_csv('/filename', encoding = encode, skiprows=skip_rows, dtype={'order postal': 'category'})\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_col_names(df):\n",
    "    characters = (' ', '/', '-')\n",
    "    for char in characters:\n",
    "        # make column names more sql friendly\n",
    "        df.columns = df.columns.str.replace(char,'_')\n",
    "        display(df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create toy SQLite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_file = '{}-all-transactions.sqlite'.format(user) # this would populate the user or variable name from the user variable cell\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data into SQLite db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_table(df,table_name):\n",
    "    df.to_sql( table_name, conn, index = False, if_exists = 'replace' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables based on available dataframes and transform column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date/time', 'settlement_id', 'type', 'sku', 'quantity', 'order_city',\n",
       "       'order_state', 'order_postal', 'product_sales', 'other', 'total'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'settlement_id', 'type', 'sku', 'quantity', 'order_city',\n",
       "       'order_state', 'order_postal', 'product_sales', 'other', 'total'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'settlement_id', 'type', 'sku', 'quantity', 'order_city',\n",
       "       'order_state', 'order_postal', 'product_sales', 'other', 'total'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a dictionary of Dataframe names and assosiated SQLite table names.\n",
    "table_map = [\n",
    "    (df,'transactions')\n",
    "    # Add additional dfs and table names here as needed\n",
    "]\n",
    "\n",
    "# Create a table for each dataframe in the table_map.\n",
    "for table in table_map:\n",
    "    df = table[0]\n",
    "    table_name = table[1]\n",
    "    # make column names more sql friendly, this should be moved out of this function, not associated with the SQLite DB only.\n",
    "    clean_col_names(df)\n",
    "    create_table(df, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start cleaning data\n",
    "User-entered data: Foibles ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize state names:\n",
    "* Create a list of all unique values in \"order_state\" column\n",
    "* Iterate through the list, determine which states are in the US states library\n",
    "* If state exists, update table with normalized name, otherwise pass (this maintains non-US place values)\n",
    "\n",
    "*Note:  This section creates a second cursor, ```update_c```, just for use in the if statement to update the table. The ```c``` cursor is the lookup cursor, so can't update itself.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ohio',),\n",
       " ('New Jersey',),\n",
       " ('Hawaii',),\n",
       " ('Missouri',),\n",
       " ('Washington',),\n",
       " ('Tennessee',),\n",
       " ('Illinois',),\n",
       " ('Virginia',),\n",
       " ('Texas',),\n",
       " ('Florida',)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a database connection and cursor object\n",
    "db_file = '{}-all-transactions.sqlite'.format(user) # this would populate the user or variable name from the user variable cell\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()\n",
    "sales_state = []\n",
    "\n",
    "# Replace any \".\" in the state names. This confuses the state lookup library\n",
    "c.execute('update transactions set order_state = replace(order_state,\".\",\"\")')\n",
    "\n",
    "# Create the list of states that will be used to look up the normalized state names.\n",
    "all_state_values = c.execute('select distinct order_state from transactions where order_state != \"\"')\n",
    "\n",
    "# Iterate through the list of states, look up whether it's a US state, and update with normalized version of name\n",
    "for value in all_state_values:\n",
    "    raw_state = (value[0])\n",
    "    \n",
    "#     print(raw_state)  # This line is for visually verifying the state being changed\n",
    "    new_state = str(us.states.lookup(raw_state))\n",
    "    if new_state != 'None': \n",
    "#         print(new_state)  # This line is also for visually verifying the state being changed ^^^\n",
    "        sales_state.append(new_state)\n",
    "        #display(sales_state) # More visual testing...\n",
    "        update_c = conn.cursor() # Create update-specific cursor, select cursor can't update its own data\n",
    "        update_c.execute('update transactions set order_state = ? where order_state = ?',(new_state,raw_state))\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Test to verify states have been updated, non-US states left in place\n",
    "new_state_values = c.execute('select distinct order_state from transactions')\n",
    "display(new_state_values.fetchmany(10))        \n",
    "\n",
    "# Commit the changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Zipcodes ###\n",
    "Create less granular groups and more interesting visualization by shortening to 5 digit zips.\n",
    "\n",
    "00000-0000 -> 00000\n",
    "\n",
    "Future: \n",
    "* This is kind of blunt because it just slices anything longer than 5 characters. What about non-US postal codes?\n",
    "* Perhaps only look for '-' in index 5 and slice then? Again, non-US consideration.\n",
    "* Would like to play with dtype category, but breaks because of NaNs. To work on in the future.\n",
    "\n",
    "[Resource on zips and dtype for leading zeros](http://data-tutorials.com/zip-codes-in-pandas.html)\n",
    "\n",
    "[Current pandas doc on dtype 'category', article above is out of date here](https://pandas.pydata.org/pandas-docs/stable/categorical.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total dataframe rows: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "49760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Raw data: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'count: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'zips with dash: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['43302-5231', '07670-3014', '96789-2046', ..., '95126-1527',\n",
       "       '28115-8010', '10024-1704'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Cleaned data: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'count: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'zips with dash: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['106-0'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A quick helper to test the number of postal codes that have '-'. Should run both before and after the string operation\n",
    "def get_dashes(df):\n",
    "    long_postals = df[df['order_postal'].str.contains('-', na = False)]\n",
    "    dash_count = len(long_postals['order_postal'])\n",
    "    return(dash_count, long_postals)\n",
    "\n",
    "# Slices the zipcode based on length:\n",
    "def clean_dashes(df):\n",
    "    long_zip_codes = df['order_postal'].str.len() > 5\n",
    "    df['order_postal'] = df['order_postal'].str.slice(0, 5)# Don't love this, would rather slice after the '-' character? What about non-US postal codes?\n",
    "    \n",
    "# Total row count to get a basesline for rows in the set:\n",
    "row_count = len(df['order_postal'])\n",
    "display('total dataframe rows: ',row_count)\n",
    "\n",
    "# Rows found to have dashes:\n",
    "raw_row_count, raw_long_postals = get_dashes(df)\n",
    "display(\"Raw data: \", 'count: ',raw_row_count, 'zips with dash: ',raw_long_postals['order_postal'].unique())\n",
    "# Now clean up the zips that have dashes:\n",
    "if raw_row_count > 0: \n",
    "    clean_dashes(df)\n",
    "else: \n",
    "    display('no long zips')\n",
    "\n",
    "# Re-check for dashes to verify changes:   \n",
    "cleaned_long_row_count, cleaned_long_postals = get_dashes(df)\n",
    "display(\"Cleaned data: \", 'count: ',cleaned_long_row_count, 'zips with dash: ',cleaned_long_postals['order_postal'].unique())\n",
    "\n",
    "    \n",
    "# Some alt code to test and incorporate:\n",
    "# long_zip_codes = df['order postal'].str.len() > 5\n",
    "# df['order postal'][long_zip_codes].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize sales data by state\n",
    "\n",
    "To Do:\n",
    "* Convert sales to int64 instead of float\n",
    "* Add sales by zip code\n",
    "* Found repeats and problems with city data. Clean it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection and cursor object\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create a unique list of US states that have sales:\n",
    "state_set = list(set(sales_state))\n",
    "\n",
    "# Iterate through the state list and sum sales by state:\n",
    "sales_by_state = []\n",
    "# sales_by_zip = []\n",
    "for state in state_set:\n",
    "    c.execute('select ?, sum(quantity) from transactions where type is \"Order\" and order_state is ?;',(state,state))\n",
    "    sales_by_state.append(c.fetchone())\n",
    "# sales_by_state = dict(sales_by_state)\n",
    "\n",
    "display(sales_by_state)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create csv of total sales by city:\n",
    "* SQL query selects city and sum quantities only for orders (not returns etc) and groups the output by city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a database connection and cursor object\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()\n",
    "\n",
    "# Sum sales by city:\n",
    "c.execute('select order_state, order_city, sum(quantity) from transactions where type is \"Order\" group by order_state, order_city;')\n",
    "\n",
    "# Export to csv:\n",
    "with open(\"sales_totals.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['order_state', 'order_city', 'quantity'])\n",
    "    writer.writerows(c.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean City###\n",
    "Dataset contains multiple versions of the same city because of case differences so convert to all caps.\n",
    "\n",
    "\n",
    "### Problems here: This isn't working, unique count value before and after cleaning is the same. Why? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(df)\n",
    "new_df['order city'] = new_df['order city'].str.upper()\n",
    "display(df)\n",
    "display(new_df)\n",
    "display(len(new_df['order city'].unique()),len(df['order city'].unique()))\n",
    "# df['order city'].fillna(False)\n",
    "\n",
    "# len(all_names['order city'].unique())\n",
    "# all_caps_df = df['order city'].str.upper()\n",
    "# len(all_caps_df['order city'].unique())\n",
    "\n",
    "# print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper code to force-close the database when it gets stuck locked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later mapping and pretty display, here's a [link to a dictionary of abbreviations and state names](http://code.activestate.com/recipes/577305-python-dictionary-of-us-states-and-territories/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
