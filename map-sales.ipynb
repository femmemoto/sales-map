{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import us\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Prep: ###\n",
    "* Read in file, skipping over top 7 rows\n",
    "* Convert 'order postal' to category dtype (first experiment with this dtype, look for weirdness...)\n",
    "* Load function to clean column names (used as db is being created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date/time</th>\n",
       "      <th>settlement id</th>\n",
       "      <th>type</th>\n",
       "      <th>order id</th>\n",
       "      <th>sku</th>\n",
       "      <th>quantity</th>\n",
       "      <th>order city</th>\n",
       "      <th>order state</th>\n",
       "      <th>order postal</th>\n",
       "      <th>product sales</th>\n",
       "      <th>other</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feb 1, 2016 12:28:08 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>105-0254632-8301849</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MARION</td>\n",
       "      <td>OH</td>\n",
       "      <td>43302-5231</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb 1, 2016 2:09:21 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Refund</td>\n",
       "      <td>103-9249887-1536265</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TENAFLY</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07670-3014</td>\n",
       "      <td>-32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feb 1, 2016 3:19:52 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>104-3152419-5177066</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MILILANI</td>\n",
       "      <td>HI</td>\n",
       "      <td>96789-2046</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feb 1, 2016 3:35:39 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>114-6293518-1467419</td>\n",
       "      <td>sku03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BLOOMFIELD</td>\n",
       "      <td>MO</td>\n",
       "      <td>63825-9505</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>11.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb 1, 2016 5:49:49 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>113-4059732-1893026</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CLIFTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07011-3215</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feb 3, 2016 1:52:11 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>112-4824706-5214658</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>REDMOND</td>\n",
       "      <td>WA</td>\n",
       "      <td>98052-6122</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feb 3, 2016 1:54:22 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>110-6682296-7137053</td>\n",
       "      <td>sku02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NASHVILLE</td>\n",
       "      <td>TN</td>\n",
       "      <td>37212-4810</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Feb 3, 2016 2:17:18 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>105-8169048-3253065</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LAKE ZURICH</td>\n",
       "      <td>IL</td>\n",
       "      <td>60047-2839</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Feb 3, 2016 1:40:23 PM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>002-5599967-6321059</td>\n",
       "      <td>sku04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALEXANDRIA</td>\n",
       "      <td>VA</td>\n",
       "      <td>22314-4755</td>\n",
       "      <td>49.99</td>\n",
       "      <td>0</td>\n",
       "      <td>33.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Feb 4, 2016 8:28:33 AM PST</td>\n",
       "      <td>6048826701</td>\n",
       "      <td>Order</td>\n",
       "      <td>102-2342223-6180238</td>\n",
       "      <td>sku01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KELLER</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>76248-4148</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date/time  settlement id    type             order id  \\\n",
       "0  Feb 1, 2016 12:28:08 AM PST     6048826701   Order  105-0254632-8301849   \n",
       "1   Feb 1, 2016 2:09:21 PM PST     6048826701  Refund  103-9249887-1536265   \n",
       "2   Feb 1, 2016 3:19:52 PM PST     6048826701   Order  104-3152419-5177066   \n",
       "3   Feb 1, 2016 3:35:39 PM PST     6048826701   Order  114-6293518-1467419   \n",
       "4   Feb 1, 2016 5:49:49 PM PST     6048826701   Order  113-4059732-1893026   \n",
       "5   Feb 3, 2016 1:52:11 AM PST     6048826701   Order  112-4824706-5214658   \n",
       "6   Feb 3, 2016 1:54:22 AM PST     6048826701   Order  110-6682296-7137053   \n",
       "7   Feb 3, 2016 2:17:18 AM PST     6048826701   Order  105-8169048-3253065   \n",
       "8   Feb 3, 2016 1:40:23 PM PST     6048826701   Order  002-5599967-6321059   \n",
       "9   Feb 4, 2016 8:28:33 AM PST     6048826701   Order  102-2342223-6180238   \n",
       "\n",
       "     sku  quantity   order city order state order postal  product sales other  \\\n",
       "0  sku01       1.0       MARION          OH   43302-5231          35.00     0   \n",
       "1  sku02       1.0      TENAFLY          NJ   07670-3014         -32.99     0   \n",
       "2  sku02       1.0     MILILANI          HI   96789-2046          32.99     0   \n",
       "3  sku03       1.0   BLOOMFIELD          MO   63825-9505          16.99     0   \n",
       "4  sku01       1.0      CLIFTON          NJ   07011-3215          35.00     0   \n",
       "5  sku02       1.0      REDMOND          WA   98052-6122          32.99     0   \n",
       "6  sku02       1.0    NASHVILLE          TN   37212-4810          32.99     0   \n",
       "7  sku01       1.0  LAKE ZURICH          IL   60047-2839          35.00     0   \n",
       "8  sku04       1.0   ALEXANDRIA          VA   22314-4755          49.99     0   \n",
       "9  sku01       1.0       KELLER       TEXAS   76248-4148          35.00     0   \n",
       "\n",
       "    total  \n",
       "0   26.12  \n",
       "1  -29.03  \n",
       "2   24.02  \n",
       "3   11.77  \n",
       "4   26.12  \n",
       "5   24.02  \n",
       "6   24.02  \n",
       "7   26.12  \n",
       "8   33.73  \n",
       "9   26.12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = 'test_client'\n",
    "\n",
    "encode = 'latin_1'\n",
    "skip_rows = 7\n",
    "df = pd.read_csv('test-sales.csv', encoding = encode, skiprows=skip_rows, dtype={'order postal': 'str'})\n",
    "\n",
    "# Would like to play with pandas dtype 'category' but breaks the zipcode string operations so for future development:\n",
    "# df = pd.read_csv('/Users/karen/Documents/Business/Agile-Merchant/clients/spontuneous/data/2017-10-17/2016Feb1-2017Oct17CustomTransaction.csv', encoding = encode, skiprows=skip_rows, dtype={'order postal': 'category'})\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_col_names(df):\n",
    "    characters = (' ', '/', '-')\n",
    "    for char in characters:\n",
    "        # make column names more sql friendly\n",
    "        df.columns = df.columns.str.replace(char,'_')\n",
    "        display(df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create toy SQLite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_file = '{}-all-transactions.sqlite'.format(client) # this would populate the client or variable name from the client variable cell\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data into SQLite db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_table(df,table_name):\n",
    "    df.to_sql( table_name, conn, index = False, if_exists = 'replace' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables based on available dataframes and transform column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date/time', 'settlement_id', 'type', 'order_id', 'sku', 'quantity',\n",
       "       'order_city', 'order_state', 'order_postal', 'product_sales', 'other',\n",
       "       'total'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'settlement_id', 'type', 'order_id', 'sku', 'quantity',\n",
       "       'order_city', 'order_state', 'order_postal', 'product_sales', 'other',\n",
       "       'total'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'settlement_id', 'type', 'order_id', 'sku', 'quantity',\n",
       "       'order_city', 'order_state', 'order_postal', 'product_sales', 'other',\n",
       "       'total'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a dictionary of Dataframe names and assosiated SQLite table names.\n",
    "table_map = [\n",
    "    (df,'transactions')\n",
    "    # Add additional dfs and table names here as needed\n",
    "]\n",
    "\n",
    "# Create a table for each dataframe in the table_map.\n",
    "for table in table_map:\n",
    "    df = table[0]\n",
    "    table_name = table[1]\n",
    "    # make column names more sql friendly, this should be moved out of this function, not associated with the SQLite DB only.\n",
    "    clean_col_names(df)\n",
    "    create_table(df, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start cleaning data\n",
    "User-entered data: Foibles ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize state names:\n",
    "* Create a list of all unique values in \"order_state\" column\n",
    "* Iterate through the list, determine which states are in the US states library\n",
    "* If state exists, update table with normalized name, otherwise pass (this maintains non-US place values)\n",
    "\n",
    "*Note:  This section creates a second cursor, ```update_c```, just for use in the if statement to update the table. The ```c``` cursor is the lookup cursor, so can't update itself.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ohio',),\n",
       " ('New Jersey',),\n",
       " ('Hawaii',),\n",
       " ('Missouri',),\n",
       " ('Washington',),\n",
       " ('Tennessee',),\n",
       " ('Illinois',),\n",
       " ('Virginia',),\n",
       " ('Texas',),\n",
       " ('Florida',),\n",
       " ('New York',),\n",
       " ('Connecticut',),\n",
       " ('Pennsylvania',),\n",
       " ('California',),\n",
       " ('Colorado',),\n",
       " ('Oregon',),\n",
       " ('Wisconsin',),\n",
       " ('Manitoba',),\n",
       " ('cornwall',),\n",
       " ('Worcs',),\n",
       " ('New Brunswick',),\n",
       " ('BC',),\n",
       " ('Ontario',),\n",
       " ('NL',),\n",
       " ('Roma',),\n",
       " (None,),\n",
       " ('Nagaland',),\n",
       " ('South Carolina',),\n",
       " ('Arkansas',),\n",
       " ('Iowa',),\n",
       " ('Arizona',),\n",
       " ('Alabama',),\n",
       " ('Maryland',),\n",
       " ('Montana',),\n",
       " ('Utah',),\n",
       " ('W Sussex',),\n",
       " ('Glos',),\n",
       " ('North Carolina',),\n",
       " ('Michigan',),\n",
       " ('Minnesota',),\n",
       " ('Kentucky',),\n",
       " ('Indiana',),\n",
       " ('Georgia',),\n",
       " ('New Hampshire',),\n",
       " ('Kansas',),\n",
       " ('Oklahoma',),\n",
       " ('Nova Scotia',),\n",
       " ('Massachusetts',),\n",
       " ('North Dakota',),\n",
       " ('Louisiana',),\n",
       " ('Maine',),\n",
       " ('West Virginia',),\n",
       " ('Nevada',),\n",
       " ('Idaho',),\n",
       " ('Alaska',),\n",
       " ('Mississippi',),\n",
       " ('New Mexico',),\n",
       " ('Nebraska',),\n",
       " ('Hampshire',),\n",
       " ('AP',),\n",
       " ('Delaware',),\n",
       " ('Wyoming',),\n",
       " ('Guam',),\n",
       " ('South Dakota',),\n",
       " ('Rhode Island',),\n",
       " ('Vermont',),\n",
       " ('District of Columbia',),\n",
       " ('Western Australia',),\n",
       " ('Nueva vizcaya',),\n",
       " ('AE',),\n",
       " ('NSW',),\n",
       " ('New South Wales',),\n",
       " ('Northern Mariana Islands',),\n",
       " ('ON',),\n",
       " ('Eastern Province',),\n",
       " ('Victoria',),\n",
       " ('western australia',),\n",
       " ('VIC',),\n",
       " ('Puerto Rico',),\n",
       " ('Dorset',),\n",
       " ('QLD',),\n",
       " ('Qld',),\n",
       " ('Alberta',),\n",
       " ('Shanghai',),\n",
       " ('Merseyside',),\n",
       " ('Herts',),\n",
       " ('Surrey',),\n",
       " ('Notts',),\n",
       " ('Birmingham',),\n",
       " ('east sussex',),\n",
       " ('Tokyo',),\n",
       " ('Metro Manila',),\n",
       " ('Vic',),\n",
       " ('AA',),\n",
       " ('Queensland',),\n",
       " ('Newfoundland',),\n",
       " ('Australia',),\n",
       " ('Singapore',),\n",
       " ('herts',),\n",
       " ('South Australia',),\n",
       " ('ONTARIO',),\n",
       " ('ACT',),\n",
       " ('Deutschland',),\n",
       " ('SA',),\n",
       " ('228233',),\n",
       " ('Dubai',),\n",
       " ('Trinidad',),\n",
       " ('Essex',),\n",
       " ('SK',),\n",
       " ('DF',),\n",
       " ('British Columbia',),\n",
       " ('vic',),\n",
       " ('Brandenburg',),\n",
       " ('Saskatchewan',),\n",
       " ('Western austalia',),\n",
       " ('PE',),\n",
       " ('Israel',),\n",
       " ('West Midlands',),\n",
       " ('AB',),\n",
       " ('VICTORIA',),\n",
       " ('Cheshire',),\n",
       " ('Co Meath',),\n",
       " ('Hong Kong',),\n",
       " ('WILAYAH PERSEKUTUAN',),\n",
       " ('N C',),\n",
       " ('Virgin Islands',),\n",
       " ('Taiwan',),\n",
       " ('Setagaya-ku',),\n",
       " ('Riyadh',),\n",
       " ('Quebec',),\n",
       " ('Hsinchu',),\n",
       " ('Tasmania',),\n",
       " ('ontario',),\n",
       " ('Lantau',),\n",
       " ('WP',),\n",
       " ('QUEENSLAND',),\n",
       " ('Bangkok',),\n",
       " ('Suffolk',),\n",
       " ('Bayern',),\n",
       " ('Tamil Nadu',),\n",
       " ('Singapur',),\n",
       " ('Zuid-Holland',),\n",
       " ('Switzerland',),\n",
       " ('MADRID',)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a database connection and cursor object\n",
    "db_file = '{}-all-transactions.sqlite'.format(client) # this would populate the client or variable name from the client variable cell\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()\n",
    "sales_state = []\n",
    "\n",
    "# Replace any \".\" in the state names. This confuses the state lookup library\n",
    "c.execute('update transactions set order_state = replace(order_state,\".\",\"\")')\n",
    "\n",
    "# Create the list of states that will be used to look up the normalized state names.\n",
    "all_state_values = c.execute('select distinct order_state from transactions where order_state != \"\"')\n",
    "\n",
    "# Iterate through the list of states, look up whether it's a US state, and update with normalized version of name\n",
    "for value in all_state_values:\n",
    "    raw_state = (value[0])\n",
    "    \n",
    "#     print(raw_state)  # This line is for visually verifying the state being changed\n",
    "    new_state = str(us.states.lookup(raw_state))\n",
    "    if new_state != 'None': \n",
    "#         print(new_state)  # This line is also for visually verifying the state being changed ^^^\n",
    "        sales_state.append(new_state)\n",
    "        #display(sales_state) # More visual testing...\n",
    "        update_c = conn.cursor() # Create update-specific cursor, select cursor can't update its own data\n",
    "        update_c.execute('update transactions set order_state = ? where order_state = ?',(new_state,raw_state))\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Test to verify states have been updated, non-US states left in place\n",
    "new_state_values = c.execute('select distinct order_state from transactions')\n",
    "display(new_state_values.fetchall())        \n",
    "\n",
    "# Commit the changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Zipcodes ###\n",
    "Create less granular groups and more interesting visualization by shortening to 5 digit zips.\n",
    "\n",
    "00000-0000 -> 00000\n",
    "\n",
    "Future: \n",
    "* This is kind of blunt because it just slices anything longer than 5 characters. What about non-US postal codes?\n",
    "* Perhaps only look for '-' in index 5 and slice then? Again, non-US consideration.\n",
    "* Would like to play with dtype category, but breaks because of NaNs. To work on in the future.\n",
    "\n",
    "[Resource on zips and dtype for leading zeros](http://data-tutorials.com/zip-codes-in-pandas.html)\n",
    "\n",
    "[Current pandas doc on dtype 'category', article above is out of date here](https://pandas.pydata.org/pandas-docs/stable/categorical.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total dataframe rows: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "49760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Raw data: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'count: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'zips with dash: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['43302-5231', '07670-3014', '96789-2046', ..., '95126-1527',\n",
       "       '28115-8010', '10024-1704'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Cleaned data: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'count: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'zips with dash: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['106-0'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A quick helper to test the number of postal codes that have '-'. Should run both before and after the string operation\n",
    "def get_dashes(df):\n",
    "    long_postals = df[df['order_postal'].str.contains('-', na = False)]\n",
    "    dash_count = len(long_postals['order_postal'])\n",
    "    return(dash_count, long_postals)\n",
    "\n",
    "# Slices the zipcode based on length:\n",
    "def clean_dashes(df):\n",
    "    long_zip_codes = df['order_postal'].str.len() > 5\n",
    "    df['order_postal'] = df['order_postal'].str.slice(0, 5)# Don't love this, would rather slice after the '-' character? What about non-US postal codes?\n",
    "    \n",
    "# Total row count to get a basesline for rows in the set:\n",
    "row_count = len(df['order_postal'])\n",
    "display('total dataframe rows: ',row_count)\n",
    "\n",
    "# Rows found to have dashes:\n",
    "raw_row_count, raw_long_postals = get_dashes(df)\n",
    "display(\"Raw data: \", 'count: ',raw_row_count, 'zips with dash: ',raw_long_postals['order_postal'].unique())\n",
    "# Now clean up the zips that have dashes:\n",
    "if raw_row_count > 0: \n",
    "    clean_dashes(df)\n",
    "else: \n",
    "    display('no long zips')\n",
    "\n",
    "# Re-check for dashes to verify changes:   \n",
    "cleaned_long_row_count, cleaned_long_postals = get_dashes(df)\n",
    "display(\"Cleaned data: \", 'count: ',cleaned_long_row_count, 'zips with dash: ',cleaned_long_postals['order_postal'].unique())\n",
    "\n",
    "    \n",
    "# Some alt code to test and incorporate:\n",
    "# long_zip_codes = df['order postal'].str.len() > 5\n",
    "# df['order postal'][long_zip_codes].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize sales data by state\n",
    "\n",
    "To Do:\n",
    "* Convert sales to int64 instead of float\n",
    "* Add sales by zip code\n",
    "* Found repeats and problems with city data. Clean it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ohio', 1873.0),\n",
       " ('Georgia', 1236.0),\n",
       " ('Kansas', 508.0),\n",
       " ('Guam', 4.0),\n",
       " ('Vermont', 124.0),\n",
       " ('Northern Mariana Islands', 2.0),\n",
       " ('Tennessee', 811.0),\n",
       " ('Nebraska', 386.0),\n",
       " ('South Carolina', 526.0),\n",
       " ('Arizona', 1003.0),\n",
       " ('Puerto Rico', 24.0),\n",
       " ('Florida', 2161.0),\n",
       " ('Oklahoma', 437.0),\n",
       " ('Wisconsin', 978.0),\n",
       " ('New Mexico', 160.0),\n",
       " ('Iowa', 536.0),\n",
       " ('Connecticut', 822.0),\n",
       " ('North Dakota', 153.0),\n",
       " ('New Hampshire', 359.0),\n",
       " ('Arkansas', 292.0),\n",
       " ('Colorado', 1092.0),\n",
       " ('North Carolina', 1339.0),\n",
       " ('Kentucky', 558.0),\n",
       " ('Washington', 1389.0),\n",
       " ('West Virginia', 217.0),\n",
       " ('Idaho', 366.0),\n",
       " ('Louisiana', 486.0),\n",
       " ('Utah', 1136.0),\n",
       " ('Mississippi', 221.0),\n",
       " ('South Dakota', 129.0),\n",
       " ('Oregon', 635.0),\n",
       " ('Maine', 249.0),\n",
       " ('Minnesota', 914.0),\n",
       " ('Massachusetts', 1627.0),\n",
       " ('Alaska', 113.0),\n",
       " ('Wyoming', 124.0),\n",
       " ('District of Columbia', 92.0),\n",
       " ('Michigan', 1452.0),\n",
       " ('Rhode Island', 160.0),\n",
       " ('Virgin Islands', 1.0),\n",
       " ('Pennsylvania', 2230.0),\n",
       " ('Virginia', 1661.0),\n",
       " ('Maryland', 1182.0),\n",
       " ('Delaware', 176.0),\n",
       " ('Indiana', 974.0),\n",
       " ('New York', 3206.0),\n",
       " ('Montana', 239.0),\n",
       " ('Missouri', 1008.0),\n",
       " ('Alabama', 458.0),\n",
       " ('Nevada', 286.0),\n",
       " ('New Jersey', 1839.0),\n",
       " ('Hawaii', 131.0),\n",
       " ('Texas', 3340.0),\n",
       " ('California', 4859.0),\n",
       " ('Illinois', 2152.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a database connection and cursor object\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create a unique list of US states that have sales:\n",
    "state_set = list(set(sales_state))\n",
    "\n",
    "# Iterate through the state list and sum sales by state:\n",
    "sales_by_state = []\n",
    "# sales_by_zip = []\n",
    "for state in state_set:\n",
    "    c.execute('select ?, sum(quantity) from transactions where type is \"Order\" and order_state is ?;',(state,state))\n",
    "    sales_by_state.append(c.fetchone())\n",
    "# sales_by_state = dict(sales_by_state)\n",
    "\n",
    "display(sales_by_state)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create csv of total sales by city:\n",
    "* SQL query selects city and sum quantities only for orders (not returns etc) and groups the output by city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a database connection and cursor object\n",
    "conn = sqlite3.connect( db_file )\n",
    "c = conn.cursor()\n",
    "\n",
    "# Sum sales by city:\n",
    "c.execute('select order_state, order_city, sum(quantity) from transactions where type is \"Order\" group by order_state, order_city;')\n",
    "\n",
    "# Export to csv:\n",
    "with open(\"sales_totals.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['order_state', 'order_city', 'quantity'])\n",
    "    writer.writerows(c.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean City###\n",
    "Dataset contains multiple versions of the same city because of case differences so convert to all caps.\n",
    "\n",
    "\n",
    "### Problems here: This isn't working, unique count value before and after cleaning is the same. Why? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(df)\n",
    "new_df['order city'] = new_df['order city'].str.upper()\n",
    "display(df)\n",
    "display(new_df)\n",
    "display(len(new_df['order city'].unique()),len(df['order city'].unique()))\n",
    "# df['order city'].fillna(False)\n",
    "\n",
    "# len(all_names['order city'].unique())\n",
    "# all_caps_df = df['order city'].str.upper()\n",
    "# len(all_caps_df['order city'].unique())\n",
    "\n",
    "# print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper code to force-close the database when it gets stuck locked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later mapping and pretty display, here's a [link to a dictionary of abbreviations and state names](http://code.activestate.com/recipes/577305-python-dictionary-of-us-states-and-territories/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
